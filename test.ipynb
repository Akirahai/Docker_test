{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec484c83",
   "metadata": {},
   "source": [
    "# Text Presidio Anonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581532d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEDICAL_LICENSE', 'IP_ADDRESS', 'CRYPTO', 'CREDIT_CARD', 'EMAIL_ADDRESS', 'LOCATION', 'US_ITIN', 'US_BANK_NUMBER', 'DATE_TIME', 'US_SSN', 'IBAN_CODE', 'PERSON', 'US_DRIVER_LICENSE', 'PHONE_NUMBER', 'NRP', 'US_PASSPORT', 'UK_NHS', 'URL']\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "analyzer = AnalyzerEngine()\n",
    "print(analyzer.get_supported_entities(language=\"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b7c950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:08<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/long_2/.cache/huggingface/hub/models--StanfordAIMI--stanford-deidentifier-base/snapshots/661b9c1c717d3165512d440abc3700c386aefab6'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "transformers_model = \"StanfordAIMI/stanford-deidentifier-base\"\n",
    "snapshot_download(repo_id=transformers_model)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "# example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "# ner_results = nlp(example)\n",
    "# print(ner_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9505089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTokenizer.from_pretrained(transformers_model)\n",
    "AutoModelForTokenClassification.from_pretrained(transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b3dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine, NerModelConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Transformer model config\n",
    "model_config = [\n",
    "    {\"lang_code\": \"en\",\n",
    "     \"model_name\": {\n",
    "         \"spacy\": \"en_core_web_sm\", # for tokenization, lemmatization\n",
    "         \"transformers\": transformers_model # for NER\n",
    "    }\n",
    "}]\n",
    "\n",
    "# Entity mappings between the model's and Presidio's\n",
    "mapping = dict(\n",
    "    PER=\"PERSON\",\n",
    "    LOC=\"LOCATION\",\n",
    "    ORG=\"ORGANIZATION\",\n",
    "    AGE=\"AGE\",\n",
    "    ID=\"ID\",\n",
    "    EMAIL=\"EMAIL\",\n",
    "    DATE=\"DATE_TIME\",\n",
    "    PHONE=\"PHONE_NUMBER\",\n",
    "    PERSON=\"PERSON\",\n",
    "    LOCATION=\"LOCATION\",\n",
    "    GPE=\"LOCATION\",\n",
    "    ORGANIZATION=\"ORGANIZATION\",\n",
    "    NORP=\"NRP\",\n",
    "    PATIENT=\"PERSON\",\n",
    "    STAFF=\"PERSON\",\n",
    "    HOSP=\"LOCATION\",\n",
    "    PATORG=\"ORGANIZATION\",\n",
    "    TIME=\"DATE_TIME\",\n",
    "    HCW=\"PERSON\",\n",
    "    HOSPITAL=\"LOCATION\",\n",
    "    FACILITY=\"LOCATION\",\n",
    "    VENDOR=\"ORGANIZATION\",\n",
    ")\n",
    "\n",
    "labels_to_ignore = [\"O\"]\n",
    "\n",
    "ner_model_configuration = NerModelConfiguration(\n",
    "    model_to_presidio_entity_mapping=mapping,\n",
    "    alignment_mode=\"expand\", # \"strict\", \"contract\", \"expand\"\n",
    "    aggregation_strategy=\"max\", # \"simple\", \"first\", \"average\", \"max\"\n",
    "    labels_to_ignore = labels_to_ignore)\n",
    "\n",
    "transformers_nlp_engine = TransformersNlpEngine(\n",
    "    models=model_config,\n",
    "    ner_model_configuration=ner_model_configuration)\n",
    "\n",
    "# Transformer-based analyzer\n",
    "analyzer = AnalyzerEngine(\n",
    "    nlp_engine=transformers_nlp_engine, \n",
    "    supported_languages=[\"en\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac089e4",
   "metadata": {},
   "source": [
    "# Image Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f3132e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5.1\n"
     ]
    }
   ],
   "source": [
    "from presidio_image_redactor import ImageAnalyzerEngine\n",
    "from PIL import Image\n",
    "from presidio_image_redactor import ImageRedactorEngine\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/home/long_2/hai/fastapi_docker/.venv/bin/tesseract.AppImage\"\n",
    "print(pytesseract.get_tesseract_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc0e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from presidio_image_redactor import ImageRedactorEngine\n",
    "\n",
    "# Get the image to redact using PIL lib (pillow)\n",
    "image = Image.open(\"images/driver_license.png\")\n",
    "\n",
    "# Initialize the engine\n",
    "engine = ImageRedactorEngine()\n",
    "\n",
    "# Redact the image with pink color\n",
    "redacted_image = engine.redact(image, language =\"en\")\n",
    "\n",
    "# save the redacted image \n",
    "redacted_image.save(\"output/redacted_new.png\")\n",
    "# uncomment to open the image for viewing\n",
    "# redacted_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
